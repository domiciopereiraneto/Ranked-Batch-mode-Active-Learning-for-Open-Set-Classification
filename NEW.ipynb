{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "OverallTests.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "xLBad68FDBtP"
      ],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMoJWCztg2Nf"
      },
      "source": [
        "# Pool-based sampling with CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCbjhs0shXpr"
      },
      "source": [
        "pip install modal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBe4P5yig2Nf"
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "\n",
        "from modAL.models import ActiveLearner, Committee\n",
        "from modAL.uncertainty import uncertainty_sampling\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from functools import partial\n",
        "from modAL.batch import uncertainty_batch_sampling\n",
        "from modAL.multilabel import *\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from modAL.models import ActiveLearner\n",
        "\n",
        "\n",
        "from IPython import display\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLBad68FDBtP"
      },
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xdJK2a0g2Nf"
      },
      "source": [
        "# imports the cifar files\n",
        "def unpickle(file):\n",
        "    import pickle\n",
        "    with open(file, 'rb') as fo:\n",
        "        dict = pickle.load(fo, encoding='bytes')\n",
        "    return dict"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNzRjTedg2Nf"
      },
      "source": [
        "# returns a image rgb array, label and label's name of the image with index im_idx\n",
        "def cifar10_img_info(data, meta, im_idx=0):\n",
        "    im = data[b'data'][im_idx, :]\n",
        "\n",
        "    im_r = im[0:1024].reshape(32, 32)\n",
        "    im_g = im[1024:2048].reshape(32, 32)\n",
        "    im_b = im[2048:].reshape(32, 32)\n",
        "\n",
        "    img = np.dstack((im_r, im_g, im_b))\n",
        "    label = data[b'labels'][im_idx]\n",
        "    category = meta[b'label_names'][data[b'labels'][im_idx]]\n",
        "\n",
        "    return img, label, category"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubkIuIzBg2Nf"
      },
      "source": [
        "# returns a image rgb array\n",
        "def img_reshape(im):\n",
        "    im_r = im[0:1024].reshape(32, 32)\n",
        "    im_g = im[1024:2048].reshape(32, 32)\n",
        "    im_b = im[2048:].reshape(32, 32)\n",
        "\n",
        "    img = np.dstack((im_r, im_g, im_b))\n",
        "    \n",
        "    return img"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1yvXspvg2Nf"
      },
      "source": [
        "# returns X and y of the dataset, X.shape = (nº of samples x features) and y.shape = (nº of samples)\n",
        "def batch_to_xy(batch):\n",
        "    X = batch[b\"data\"]\n",
        "    y = batch[b\"labels\"]\n",
        "    y = np.array(y)\n",
        "    y.reshape(y.shape[0])\n",
        "    return X, y"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pitR8RZv1cU0"
      },
      "source": [
        "from keras.optimizers import SGD\n",
        "def create_keras_model():\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Dense(10, activation='softmax'))\n",
        "\t# compile model\n",
        "\topt = SGD(lr=0.001, momentum=0.9)\n",
        "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\treturn model"
      ],
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGcnPC1sg2Nf"
      },
      "source": [
        "## The dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yL8rXtczg2Nf"
      },
      "source": [
        "# batch with 10000 examples\n",
        "batch1 = unpickle(\"data_batch_1\")\n",
        "# meta has the labels' names\n",
        "meta = unpickle(\"batches.meta\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXd26JX7D6iR"
      },
      "source": [
        "## Principal component analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5QE_Aqpg2Nh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d59f4453-3785-44d6-f652-14da57b18d31"
      },
      "source": [
        "X_raw, Y_raw = batch_to_xy(batch1)\n",
        "\n",
        "#APPLY PCA\n",
        "#https://towardsdatascience.com/integration-of-dimension-reduction-methods-and-neural-network-for-image-classification-96281963fe24\n",
        "#99% -> 658\n",
        "#95% -> 217\n",
        "#90% -> 99\n",
        "#80% -> 21\n",
        "RANDOM_STATE_SEED = 123\n",
        "np.random.seed(RANDOM_STATE_SEED)\n",
        "pca = PCA(n_components=21, random_state=RANDOM_STATE_SEED)\n",
        "tf_X = pca.fit_transform(X=X_raw)\n",
        "print(tf_X.shape)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 21)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byV37OOqg2Nh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ea917e6-f348-4c75-91fc-f2aa669437c5"
      },
      "source": [
        "# Isolate our examples for our labeled dataset.\n",
        "n_labeled = tf_X.shape[0]   #Number of samples\n",
        "training_indices = np.random.choice(n_labeled, size=1500)\n",
        "\n",
        "X_train = tf_X[training_indices]\n",
        "y_train = Y_raw[training_indices]\n",
        "\n",
        "# Isolate the non-training examples we'll be querying.\n",
        "X_pool = np.delete(tf_X, training_indices, axis=0)\n",
        "y_pool = np.delete(Y_raw, training_indices, axis=0)\n",
        "\n",
        "X_train.shape"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1500, 21)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSDD0_P8g2Ni"
      },
      "source": [
        "## Ranked Bacth Mode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X490i0tgC4sY"
      },
      "source": [
        "# Specify our core estimator.\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "# Pre-set our batch sampling to retrieve 3 samples at a time.\n",
        "BATCH_SIZE = 30\n",
        "preset_batch = partial(uncertainty_batch_sampling, n_instances=BATCH_SIZE)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUsJKVupg2Ni"
      },
      "source": [
        "learner = ActiveLearner(\n",
        "    estimator=RandomForestClassifier(),\n",
        "    X_training=X_train,\n",
        "    y_training=y_train,\n",
        "    query_strategy=preset_batch\n",
        ")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfFkFEDxx0wp",
        "outputId": "0d7b62ad-ab4b-49d5-f3fd-d131ce2400d9"
      },
      "source": [
        "# Record our learner's score on the raw data.\n",
        "unqueried_score = learner.score(tf_X, Y_raw)\n",
        "print('Ranked Batch Mode Approach Score: {acc:0.4f}'.format(acc=unqueried_score*100))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ranked Batch Mode Approach Score: 44.4600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZReHGrIwUSYr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9093ffae-442a-4d5e-e5ba-0deaa404d45d"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1500, 21)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02MAPRnFIniS"
      },
      "source": [
        "## Multilabel SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJAoD5-UIqti"
      },
      "source": [
        "learner = ActiveLearner(\n",
        "    estimator=OneVsRestClassifier(SVC(probability=True, gamma='auto')),\n",
        "    X_training=X_train,\n",
        "    y_training = y_train,\n",
        "    query_strategy=avg_score\n",
        ")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIutS9rTI8k-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09e3a48f-320b-454d-e3ef-fb39f86113bc"
      },
      "source": [
        "# Record our learner's score on the raw data.\n",
        "unqueried_score2 = learner.score(tf_X, Y_raw)\n",
        "print('Multilabel SVM Approach Score: {acc:0.4f}'.format(acc=unqueried_score2*100))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Multilabel SVM Approach Score: 22.7200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csbTUbnpJoMz"
      },
      "source": [
        "## Query by comittee"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trPRXUGzJsVL"
      },
      "source": [
        "# initializing Committee members\n",
        "n_members = 5\n",
        "learner_list = list()\n",
        "\n",
        "qbc_X_pool = tf_X;\n",
        "qbc_y_pool = Y_raw;\n",
        "\n",
        "for member_idx in range(n_members):\n",
        "    train_idx = np.random.choice(qbc_X_pool.shape[0], size=300, replace=False)\n",
        "    qbc_X_train = qbc_X_pool[train_idx]\n",
        "    qbc_y_train = qbc_y_pool[train_idx]\n",
        "\n",
        "    # creating a reduced copy of the data with the known instances removed\n",
        "    qbc_X_pool = np.delete(qbc_X_pool, train_idx, axis=0)\n",
        "    qbc_y_pool = np.delete(qbc_y_pool, train_idx)\n",
        "\n",
        "    # initializing learner\n",
        "    learner = ActiveLearner(\n",
        "        estimator=RandomForestClassifier(),\n",
        "        X_training=qbc_X_train, y_training=qbc_y_train\n",
        "    )\n",
        "    learner_list.append(learner)\n",
        "\n",
        "# assembling the committee\n",
        "committee = Committee(learner_list=learner_list)\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKsj1Tv1Oa9o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "503ad18c-7643-4ea8-9462-fc367e291dd0"
      },
      "source": [
        "# Record our learner's score on the raw data.\n",
        "unqueried_score3 = committee.score(tf_X,Y_raw)\n",
        "print('Query by Committee Approach Score: {acc:0.4f}'.format(acc=unqueried_score3*100))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Query by Committee Approach Score: 45.5500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FARJ0YOKvcox"
      },
      "source": [
        "## Deep Bayesian - CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4uEXIHevgs6",
        "outputId": "43a8c210-424e-41c9-db85-cfedcf9d93b0"
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "# create the classifier\n",
        "classifier = KerasClassifier(create_keras_model)\n",
        "\n",
        "\n",
        "a = X_raw[training_indices]\n",
        "b = Y_raw[training_indices]\n",
        "\n",
        "Xk_train = tf.reshape(a, [-1,32,32,3])\n",
        "Xk_test = tf.reshape(X_raw, [-1,32,32,3])\n",
        "\n",
        "Yk_train = keras.utils.to_categorical(y_train, 10)\n",
        "Yk_test = keras.utils.to_categorical(Y_raw, 10)\n",
        "\n",
        "\n",
        "print(Xk_test.shape)\n",
        "# initialize ActiveLearner\n",
        "keras = ActiveLearner(\n",
        "    estimator=classifier,\n",
        "    X_training=Xk_train, \n",
        "    y_training=Yk_train\n",
        ")\n",
        "\n",
        "unqueried_score4 = keras.score(Xk_test, Yk_test)\n",
        "print('Query by Keras Approach Score: {acc:0.4f}'.format(acc=unqueried_score4*100))"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 32, 32, 3)\n",
            "47/47 [==============================] - 10s 220ms/step - loss: nan - accuracy: 0.1033\n",
            "313/313 [==============================] - 18s 58ms/step - loss: nan - accuracy: 0.1005\n",
            "Query by Keras Approach Score: 10.0500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQ9AvSM9Vm0c"
      },
      "source": [
        "## Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjtN-V71VpvE",
        "outputId": "0e0d5b29-7cbc-4724-cfca-ebffe35dd6ee"
      },
      "source": [
        "print('Ranked Batch Mode Approach Score: {acc:0.4f}'.format(acc=unqueried_score*100))\n",
        "print('Multilabel SVM Approach Score: {acc:0.4f}'.format(acc=unqueried_score2*100))\n",
        "print('Query by Committee Approach Score: {acc:0.4f}'.format(acc=unqueried_score3*100))\n",
        "print('CNN Approach Score: {acc:0.4f}'.format(acc=unqueried_score4*100))"
      ],
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ranked Batch Mode Approach Score: 44.4600\n",
            "Multilabel SVM Approach Score: 22.7200\n",
            "Query by Committee Approach Score: 45.5500\n",
            "CNN Approach Score: 10.0500\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}